{"cells":[{"cell_type":"markdown","metadata":{"id":"world"},"source":["# A"]},{"cell_type":"markdown","metadata":{},"source":["**Anomaly detection**\n","\n","---\n","\n","Picking out new, anomalous data points based on training with many \"normal\" instances\n","\n","<img src=\"img/anomaly_detection.png\" width=\"25%\">\n","\n","Typically, the challenge with this task is gathering a very \"clean\" training set that is representative of most normal values"]},{"cell_type":"markdown","metadata":{},"source":["**Association rule learning**\n","\n","---\n","\n","Digging into large amounts of data and discovering interesting **trends between features**\n","\n","e.g. discovering the association between customer's buying BBQ sauce and burgers"]},{"cell_type":"markdown","metadata":{},"source":["**Attribute**\n","\n","---\n","\n","A data type/column present in the data\n","\n","e.g. \"mileage\""]},{"cell_type":"markdown","metadata":{},"source":["**AUC**\n","\n","---\n","\n","The AUC (Area Under Curve) is the area underneath a ROC curve, a higher value of this typically means a better performing classifier (as there will be fewer false positives).\n","\n","You can use the roc_auc_score() function from SciKit-Learn to calculate this"]},{"cell_type":"markdown","metadata":{},"source":["# B"]},{"cell_type":"markdown","metadata":{},"source":["**Batch learning**\n","\n","---\n","\n","The system is incapable of learning incrementally - it must be trained with **all available data**\n","\n","This requires a lot of time and resources so is typically done **\"offline\"** and then a static model is brought into production and runs without learning anymore\n","\n","<img src=\"img/batch_learning.png\" width=\"25%\" >"]},{"cell_type":"markdown","metadata":{},"source":["# C"]},{"cell_type":"markdown","metadata":{},"source":["**Cost function**\n","\n","---\n","\n","A function that measures how **bad** a model performs so it can improve itself"]},{"cell_type":"markdown","metadata":{},"source":["**Cross-validation**\n","\n","---\n","\n","**Splitting** the validation dataset into many **smaller sets** and evaluating the model once against each subset. Then, the model's errors can be averaged out to get a better representation of its performance (by ensuring it doesn't overfit to a large validation dataset).\n","\n","However, the training time is now multiplied by the number of subsets"]},{"cell_type":"markdown","metadata":{},"source":["**Confusion matrix**\n","\n","---\n","\n","A confusion matrix is a grid with the number of false positives/negatives and true positives/negatives. It's therefore a good way of measuring classification models' performance\n","\n","<img src=\"img/confusion_matrix.png\" width=\"25%\">\n","\n","**Rows = actual classes**\n","\n","**Columns = predicted classes**"]},{"cell_type":"markdown","metadata":{},"source":["# D"]},{"cell_type":"markdown","metadata":{},"source":["**Data mining**\n","\n","---\n","\n","Digging into large amounts of data and discovering **patterns** that were *not immediately apparent* (with ML techniques)"]},{"cell_type":"markdown","metadata":{},"source":["**Dimensionality reduction**\n","\n","---\n","\n","Simplifying a dataset without losing too much information. The goal is to improve performance and make the dataset easier to visualise"]},{"cell_type":"markdown","metadata":{},"source":["# E"]},{"cell_type":"markdown","metadata":{},"source":["# F"]},{"cell_type":"markdown","metadata":{},"source":["**Feature extraction**\n","\n","---\n","\n","Merging multiple **related** columns into one feature that represents them all\n","\n","e.g. a car's mileage may be strongly related to its age, so we could extract these two columns into one representing its general \"wear and tear\""]},{"cell_type":"markdown","metadata":{},"source":["**$F_1$ score**\n","\n","---\n","\n","A combination of the precision and recall metrics into one metric - the harmonic mean of those two put together\n","\n","$F_1=\\frac{2}{{\\frac{1}{precision}}+{\\frac{1}{recall}}}$\n","\n","This is more sensitive to lower values of one of the metrics, so a model only scores well if both are high or both are similar. Sometimes, this isn't what we want, we might want a model to be more accurate (e.g. when classifying safe content) and sacrifice recall (as it false negatives don't matter as much)\n","\n","<img src=\"img/precision_recall_tradeoff.png\" width=\"25%\">"]},{"cell_type":"markdown","metadata":{},"source":["**Feature**\n","\n","---\n","\n","An **attribute** plus its value\n","\n","e.g. \"mileage = 15,000\""]},{"cell_type":"markdown","metadata":{},"source":["# G"]},{"cell_type":"markdown","metadata":{},"source":["# H"]},{"cell_type":"markdown","metadata":{},"source":["**Hyperparameter tuning**\n","\n","---\n","\n","Once we have chosen a model, we need to choose its hyperparameters (i.e. its parameters for training).\n","\n","This is done by evaluating it against a test dataset and tweaking the values (either automatically or manually) until the lowest regularisation error is found. Then, this optimal model needs to be checked against a validation set to ensure that its hyperparameters aren't simply tuned for the test set -> this is called **holdout validation**"]},{"cell_type":"markdown","metadata":{},"source":["# I"]},{"cell_type":"markdown","metadata":{},"source":["**Instance-based learning**\n","\n","---\n","\n","The system will learn each case off by heart and then generate a **\"similarity measure\"** to compare new instances to any previous ones\n","\n","<img src=\"img/instance_based_learning.png\" width=\"25%\" >"]},{"cell_type":"markdown","metadata":{},"source":["# J"]},{"cell_type":"markdown","metadata":{},"source":["# K"]},{"cell_type":"markdown","metadata":{},"source":["**K-fold cross-validation**\n","\n","---\n","\n","Instead of splitting the dataset into train and test, we can randomly select $k$ folds that will split the training dataset into distinct subsets. \n","\n","K-fold cross-validation will then train the model $k$ times, holding back one of the folds for validation and using the others for training data.\n","\n","<img src=\"img/k_fold_cross_validation.jpg\" width=\"25%\">"]},{"cell_type":"markdown","metadata":{},"source":["# L"]},{"cell_type":"markdown","metadata":{},"source":["**Learning rate**\n","\n","---\n","\n","How fast a model should adapt to changing data\n","\n","High learning rate = system will rapidly adapt *but* will **forget** old data quickly\n","\n","Low learning rate = system will adapt more slowly *but* will be **less sensitive** to outliers"]},{"cell_type":"markdown","metadata":{},"source":["# M"]},{"cell_type":"markdown","metadata":{},"source":["**Machine learning**\n","\n","---\n","\n","The science (and art) of programming computers so they can *learn from data*.\n","\n","Traditionally, we write programs with a series of hard-coded rules based on data. Machine learning is an alternate approach that allows the computer to define these rules for itself and adjust them as the data changes\n","\n","The main data challenges of ML are:\n","* Insufficient **quantity** of data -> typically need thousands or millions of samples, data is usually more important than algorithm\n","* **Nonrepresentative** training data -> in order to generalise well, you need training data that is representative of the whole population\n","* **Poor quality** data -> data needs to be cleansed of outliers or errors so the model doesn't try to account for them\n","* Irrelevant features -> rubbish in, rubbish out - need to keep only relevant features and discard unrelated ones\n","\n","The main algorithm challenges of ML are:\n","* Overfitting\n","* Underfitting\n","* The trade-off between validation and training time"]},{"cell_type":"markdown","metadata":{},"source":["**Mean absolute error (MAE)**\n","\n","---\n","\n","An equation that measures the average error a model makes, similar to RMSE, but without adjusting as much for big outliers (no squaring and square rooting).\n","\n","Used when outliers are common\n","\n","$MAE\\left(X,h\\right)=\\frac{1}{m}\\sum_{i=1}^{m}\\left|h\\left(x^{\\left(i\\right)}\\right)-y^{\\left(i\\right)}\\right|$"]},{"cell_type":"markdown","metadata":{},"source":["**Min-max scaling**\n","\n","---\n","\n","Min-max scaling (or normalisation) is where values are shifted and rescaled so they lie between 0 and 1.\n","\n","It works by subtracting the min from the current value and dividing by the max.\n","\n","This always guarantees the range of the values, but can be severely affected by outliers"]},{"cell_type":"markdown","metadata":{},"source":["**Model**\n","\n","---\n","\n","Can refer to\n","* The type of model (e.g. Linear Regression)\n","* A fully specified model architecture (e.g. Linear Regression with one input and one output)\n","* The final trained model ready to be used for predictions (e.g. Linear Regression with one input and one output, using x = 4.85 and x2 = 4.91 x 10^-5"]},{"cell_type":"markdown","metadata":{},"source":["**Model-based learning**\n","\n","---\n","\n","An alternative to instance-based learning for generalising from a set of examples is to create a model that can **\"predict\"** new instances\n","\n","<img src=\"img/model_based_learning.png\" width=\"25%\">"]},{"cell_type":"markdown","metadata":{},"source":["**Multiple regression**\n","\n","---\n","\n","When the system uses **multiple features** to make a prediction"]},{"cell_type":"markdown","metadata":{},"source":["**Multivariate regression**\n","\n","---\n","\n","A regression task where the goal is to predict **multiple values** per set of inputs"]},{"cell_type":"markdown","metadata":{},"source":["**Multilabel classification**\n","\n","---\n","\n","Being able to classify an instance as being more than one class.\n","\n","e.g. this photo contains these three people"]},{"cell_type":"markdown","metadata":{},"source":["**Multioutput classification**\n","\n","---\n","\n","This is a generalisation of multilabel classification where each label can contain more than 2 possible values. \n","\n","An example could be a classifier that denoises images - its inputs would be multilabel (with each pixel being a label) and it would be multioutput for each of these labels (giving us an intensity value from 0-255). The classifier will learn to categorise noisy pixels and remove them"]},{"cell_type":"markdown","metadata":{},"source":["# N"]},{"cell_type":"markdown","metadata":{},"source":["# O"]},{"cell_type":"markdown","metadata":{},"source":["**One-hot encoding**\n","\n","---\n","\n","Creates one binary attribute (column) per text category that will be 1 if that category is true, or 0 if it is not.\n","\n","Standard way of encoding text categories as numbers.\n","\n","<img src=\"img/one_hot_encoding.jpg\" width=\"25%\">"]},{"cell_type":"markdown","metadata":{},"source":["**Online learning**\n","\n","---\n","\n","The system can be trained incrementally by feeding it single data instances sequentially, either individually or in small \"mini-batches\"\n","\n","Each learning step must be fast and cheap so that it can learn on the fly\n","\n","Best used for quickly-changing data (such as stocks)\n","\n","<img src=\"img/online_learning.png\" width=\"25%\" >"]},{"cell_type":"markdown","metadata":{},"source":["**Overfitting**\n","\n","---\n","\n","When a model replicates its training dataset too closely and **lose the ability to generalise**. It happens when the model is **too complex** relative to the amount and noisiness of the training data.\n","\n","You can tell a model is overfitting when the training/validation error is low but the generalisation error is high\n","\n","<img src=\"img/overfitting.png\" width=\"25%\" >\n","\n","Solutions:\n","* Simplify the model by choosing one with fewer parameters (e.g. linear rather than polynomial)\n","* Reduce the number of attributes in the training dataset\n","* Restrict the model's parameters (regularisation)\n","* Gather more training data\n","* Reduce noise in training data (e.g. fix errors and remove outliers)"]},{"cell_type":"markdown","metadata":{},"source":["**OvR strategy**\n","\n","---\n","\n","One-versus-the-rest is a strategy for multiclass classification where a binary classifier is trained for every class.\n","\n","Assuming $n$ classes, we will need $n$ classifiers that will have to be trained on the **whole** dataset\n","\n","This tends to be more effective on small to medium sized datasets, depending on the algorithm, and is **generally preferred** over OvO"]},{"cell_type":"markdown","metadata":{},"source":["**OvO strategy**\n","\n","---\n","\n","One-versus-one is a strategy for multiclass classification where a binary classifier is trained for every **pair** of classes.\n","\n","e.g. for MNIST we would have one classifier that distinguishes 0s from 1s, one that distinguishes 1s from 2s etc.\n","\n","Assuming $n$ classes, we will need $\\frac{n(n-1)}{2}$ classifiers that can be trained on part of the dataset.\n","\n","This tends to be more effective on massive datasets, depending on the algorithm"]},{"cell_type":"markdown","metadata":{},"source":["# P"]},{"cell_type":"markdown","metadata":{},"source":["**Pipeline**\n","\n","---\n","\n","A sequence of data processing components to transform data from the source to the end goal\n","\n","<img src=\"img/pipeline.png\" width=\"25%\">"]},{"cell_type":"markdown","metadata":{},"source":["**Precision**\n","\n","---\n","\n","The number of true positives over all positives. Typically used along with recall to get a good picture of a classifier models' performance\n","\n","$precision=\\frac{TP}{TP+FP}$\n","\n","High precision = fewer false positives, more false negatives"]},{"cell_type":"markdown","metadata":{},"source":["# Q"]},{"cell_type":"markdown","metadata":{},"source":["# R"]},{"cell_type":"markdown","metadata":{},"source":["**Random forest algorithm**\n","\n","---\n","\n","Used for regression or classification and works by training many decision trees on random subsets of data, and then averaging out their predictions"]},{"cell_type":"markdown","metadata":{},"source":["**Regularisation**\n","\n","---\n","\n","Constraining a model to make it simpler and reduce the risk of **overfitting**\n","\n","e.g. force the slope of a linear model to be smaller to reduce degrees of freedom -> this may fit worse with training data but be more generalisable\n","\n","<img src=\"img/regularisation.png\" width=\"25%\">\n","\n","*in the above image, circles are training data and squares are new data*"]},{"cell_type":"markdown","metadata":{},"source":["**Reinforcement learning**\n","\n","---\n","\n","Where the learning system (agent) can observe the environment, carry out actions and then gets either a **reward** or **penalty**. It must then learn the best strategy over time to maximise the reward\n","\n","<img src=\"img/reinforcement.png\" width=\"25%\" />\n","\n","e.g. AIs can analyse historical results and then play millions of games against themselves to find the best policy to win"]},{"cell_type":"markdown","metadata":{},"source":["**Root Mean Square Error (RMSE)**\n","\n","---\n","\n","An equation that measures the **average error** a system makes in its predictions and **gives more weight to higher errors** (hence the square root).\n","\n","Used when outliers are rare.\n","\n","$ RMSE(X, h) = \\sqrt{\\frac{1}{m}\\Sigma_{i=1}^{m}{\\Big({h(x^{(i)})-y^{(i)}}\\Big)^2}} $\n","\n","Where $m$ is the number of instances in the validation dataset that you are evaluating RMSE on\n","\n","$x^{(i)}$ is a vector with all the feature values for the $i^{th}$ instance\n","\n","e.g. $x^{1}$ might be $\\left(\\begin{matrix}-118.29\\\\33.91\\\\\\begin{matrix}1,416\\\\38,372\\\\\\end{matrix}\\\\\\end{matrix}\\right)$ (the first item in the dataset)\n","\n","$y^{i}$ is simply the label (desired output for that instance)\n","\n","Finally, $X$ is a matrix containing all the feature values and $h$ is the prediction function that gives us the value to evaluate"]},{"cell_type":"markdown","metadata":{},"source":["**Recall**\n","\n","---\n","\n","The ratio of correctly identified positives (a.k.a the sensitivity or True Positive Rate)\n","\n","$recall=\\frac{TP}{TP+FN}$\n","\n","High recall = fewer false negatives, more false positives"]},{"cell_type":"markdown","metadata":{},"source":["**ROC curve**\n","\n","---\n","\n","The receiver operating chracteristic (ROC) curve plots the recall (True Positive Rate) against the False Positive Rate. Therefore, the ROC curve helps us compare classifiers' performance and find the optimal threshold for a classifier by looking at when the TPR is high and the FPR is low\n","\n","<img src=\"img/roc_curve.jpg\" width=\"25%\">"]},{"cell_type":"markdown","metadata":{},"source":["# S"]},{"cell_type":"markdown","metadata":{},"source":["**Semisupervised learning**\n","\n","---\n","\n","A machine learning system that can deal with a combination of labelled and unlabelled data. They often use a combination of supervised and unsupervised algorithms\n","\n","<img src=\"img/semisupervised.png\" width=\"25%\" />\n","\n","e.g. the unlabelled circles in the image above help classify a new instance (the cross) as a triangle and not a square - this can be done with a combination of clustering and classification algorithms\n","\n","e.g. Google Photos allows you to label a person once and then will identify all the photos that person has appeared in"]},{"cell_type":"markdown","metadata":{},"source":["**Standardisation**\n","\n","---\n","\n","A method of bringing all data values onto the same scale. It subtracts the mean value from the current, and divides by the standard deviation.\n","\n","This results in data with a standard deviation of 1 and is good at **ignoring outliers**, but does not guarantee data lies **within a specific range**.\n","\n","<img src=\"img/standardisation.png\" width=\"25%\" />"]},{"cell_type":"markdown","metadata":{},"source":["**Supervised learning**\n","\n","---\n","\n","A machine learning system where you provide the desired solutions (called **labels**) in the training data\n","\n","<img src=\"img/supervised.png\" width=\"25%\" />\n","\n","Examples of supervised techniques:\n","* Classification\n","* Regression\n","* Neural networks"]},{"cell_type":"markdown","metadata":{},"source":["# T"]},{"cell_type":"markdown","metadata":{},"source":["# U"]},{"cell_type":"markdown","metadata":{},"source":["**Underfitting**\n","\n","--- \n","\n","When the model is **too simple** to learn the underlying structure of your training data and its **predictions are always inaccurate**, even on training data\n","\n","Solutions:\n","* Select a more powerful model, with more parameters\n","* Feed better features to the learning algorithm (feature engineering)\n","* Reduce the constraints on the model (reduce any regularisation hyperparameters)"]},{"cell_type":"markdown","metadata":{},"source":["**Univariate regression**\n","\n","---\n","\n","A regression task where the goal is to only predict **one value** per set of inputs"]},{"cell_type":"markdown","metadata":{},"source":["**Unsupervised learning**\n","\n","---\n","\n","A machine learning system where the training data is **unlabelled**. The system tries to learn without a teacher\n","\n","<img src=\"img/unsupervised.png\" width=\"25%\" />\n","\n","Examples of unsupervised techniques:\n","* Clustering\n","* Anomaly detection\n","* Visualisation/dimensionality reduction\n","* Association rule learning"]},{"cell_type":"markdown","metadata":{},"source":["**Utility/fitness function**\n","\n","--- \n","\n","A function that measures how well a model is performing so it can improve itself"]},{"cell_type":"markdown","metadata":{},"source":["# V"]},{"cell_type":"markdown","metadata":{},"source":["# W"]},{"cell_type":"markdown","metadata":{},"source":["# X"]},{"cell_type":"markdown","metadata":{},"source":["# Y"]},{"cell_type":"markdown","metadata":{},"source":["# Z"]}],"metadata":{"colab":{"name":"Glossary.ipynb","provenance":[],"toc_visible":true},"interpreter":{"hash":"e1d159cb68591e48b67255eb41f9bda52bbf3bbfb0350e464e82f881b338c8a1"},"kernelspec":{"display_name":"Python 3.7.4 64-bit (conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":0}
