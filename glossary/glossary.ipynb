{"cells":[{"cell_type":"markdown","metadata":{"id":"world"},"source":["# A"]},{"cell_type":"markdown","metadata":{},"source":["**Anomaly detection**\n","\n","---\n","\n","Picking out new, anomalous data points based on training with many \"normal\" instances\n","\n","<img src=\"img/anomaly_detection.png\" width=\"25%\">\n","\n","Typically, the challenge with this task is gathering a very \"clean\" training set that is representative of most normal values"]},{"cell_type":"markdown","metadata":{},"source":["**Association rule learning**\n","\n","---\n","\n","Digging into large amounts of data and discovering interesting **trends between features**\n","\n","e.g. discovering the association between customer's buying BBQ sauce and burgers"]},{"cell_type":"markdown","metadata":{},"source":["**Attribute**\n","\n","---\n","\n","A data type/column present in the data\n","\n","e.g. \"mileage\""]},{"cell_type":"markdown","metadata":{},"source":["# B"]},{"cell_type":"markdown","metadata":{},"source":["**Batch learning**\n","\n","---\n","\n","The system is incapable of learning incrementally - it must be trained with **all available data**\n","\n","This requires a lot of time and resources so is typically done **\"offline\"** and then a static model is brought into production and runs without learning anymore\n","\n","<img src=\"img/batch_learning.png\" width=\"25%\" >"]},{"cell_type":"markdown","metadata":{},"source":["# C"]},{"cell_type":"markdown","metadata":{},"source":["**Cost function**\n","\n","---\n","\n","A function that measures how **bad** a model performs so it can improve itself"]},{"cell_type":"markdown","metadata":{},"source":["**Cross-validation**\n","\n","---\n","\n","**Splitting** the validation dataset into many **smaller sets** and evaluating the model once against each subset. Then, the model's errors can be averaged out to get a better representation of its performance (by ensuring it doesn't overfit to a large validation dataset).\n","\n","However, the training time is now multiplied by the number of subsets"]},{"cell_type":"markdown","metadata":{},"source":["# D"]},{"cell_type":"markdown","metadata":{},"source":["**Data mining**\n","\n","---\n","\n","Digging into large amounts of data and discovering **patterns** that were *not immediately apparent* (with ML techniques)"]},{"cell_type":"markdown","metadata":{},"source":["**Dimensionality reduction**\n","\n","---\n","\n","Simplifying a dataset without losing too much information. The goal is to improve performance and make the dataset easier to visualise"]},{"cell_type":"markdown","metadata":{},"source":["# E"]},{"cell_type":"markdown","metadata":{},"source":["# F"]},{"cell_type":"markdown","metadata":{},"source":["**Feature extraction**\n","\n","---\n","\n","Merging multiple **related** columns into one feature that represents them all\n","\n","e.g. a car's mileage may be strongly related to its age, so we could extract these two columns into one representing its general \"wear and tear\""]},{"cell_type":"markdown","metadata":{},"source":["**Feature**\n","\n","---\n","\n","An **attribute** plus its value\n","\n","e.g. \"mileage = 15,000\""]},{"cell_type":"markdown","metadata":{},"source":["# G"]},{"cell_type":"markdown","metadata":{},"source":["# H"]},{"cell_type":"markdown","metadata":{},"source":["**Hyperparameter tuning**\n","\n","---\n","\n","Once we have chosen a model, we need to choose its hyperparameters (i.e. its parameters for training).\n","\n","This is done by evaluating it against a test dataset and tweaking the values (either automatically or manually) until the lowest regularisation error is found. Then, this optimal model needs to be checked against a validation set to ensure that its hyperparameters aren't simply tuned for the test set -> this is called **holdout validation**"]},{"cell_type":"markdown","metadata":{},"source":["# I"]},{"cell_type":"markdown","metadata":{},"source":["**Instance-based learning**\n","\n","---\n","\n","The system will learn each case off by heart and then generate a **\"similarity measure\"** to compare new instances to any previous ones\n","\n","<img src=\"img/instance_based_learning.png\" width=\"25%\" >"]},{"cell_type":"markdown","metadata":{},"source":["# J"]},{"cell_type":"markdown","metadata":{},"source":["# K"]},{"cell_type":"markdown","metadata":{},"source":["**K-fold cross-validation**\n","\n","---\n","\n","Instead of splitting the dataset into train and test, we can randomly select $k$ folds that will split the training dataset into distinct subsets. \n","\n","K-fold cross-validation will then train the model $k$ times, holding back one of the folds for validation and using the others for training data.\n","\n","<img src=\"img/k_fold_cross_validation.jpg\" width=\"25%\">"]},{"cell_type":"markdown","metadata":{},"source":["# L"]},{"cell_type":"markdown","metadata":{},"source":["**Learning rate**\n","\n","---\n","\n","How fast a model should adapt to changing data\n","\n","High learning rate = system will rapidly adapt *but* will **forget** old data quickly\n","\n","Low learning rate = system will adapt more slowly *but* will be **less sensitive** to outliers"]},{"cell_type":"markdown","metadata":{},"source":["# M"]},{"cell_type":"markdown","metadata":{},"source":["**Machine learning**\n","\n","---\n","\n","The science (and art) of programming computers so they can *learn from data*.\n","\n","Traditionally, we write programs with a series of hard-coded rules based on data. Machine learning is an alternate approach that allows the computer to define these rules for itself and adjust them as the data changes\n","\n","The main data challenges of ML are:\n","* Insufficient **quantity** of data -> typically need thousands or millions of samples, data is usually more important than algorithm\n","* **Nonrepresentative** training data -> in order to generalise well, you need training data that is representative of the whole population\n","* **Poor quality** data -> data needs to be cleansed of outliers or errors so the model doesn't try to account for them\n","* Irrelevant features -> rubbish in, rubbish out - need to keep only relevant features and discard unrelated ones\n","\n","The main algorithm challenges of ML are:\n","* Overfitting\n","* Underfitting\n","* The trade-off between validation and training time"]},{"cell_type":"markdown","metadata":{},"source":["**Model**\n","\n","---\n","\n","Can refer to\n","* The type of model (e.g. Linear Regression)\n","* A fully specified model architecture (e.g. Linear Regression with one input and one output)\n","* The final trained model ready to be used for predictions (e.g. Linear Regression with one input and one output, using x = 4.85 and x2 = 4.91 x 10^-5"]},{"cell_type":"markdown","metadata":{},"source":["**Model-based learning**\n","\n","---\n","\n","An alternative to instance-based learning for generalising from a set of examples is to create a model that can **\"predict\"** new instances\n","\n","<img src=\"img/model_based_learning.png\" width=\"25%\">"]},{"cell_type":"markdown","metadata":{},"source":["**Multiple regression**\n","\n","---\n","\n","When the system uses **multiple features** to make a prediction"]},{"cell_type":"markdown","metadata":{},"source":["**Multivariate regression**\n","\n","---\n","\n","A regression task where the goal is to predict **multiple values** per set of inputs"]},{"cell_type":"markdown","metadata":{},"source":["**Mean absolute error (MAE)**\n","\n","---\n","\n","An equation that measures the average error a model makes, similar to RMSE, but without adjusting as much for big outliers (no squaring and square rooting).\n","\n","Used when outliers are common\n","\n","$MAE\\left(X,h\\right)=\\frac{1}{m}\\sum_{i=1}^{m}\\left|h\\left(x^{\\left(i\\right)}\\right)-y^{\\left(i\\right)}\\right|$"]},{"cell_type":"markdown","metadata":{},"source":["**Min-max scaling**\n","\n","---\n","\n","Min-max scaling (or normalisation) is where values are shifted and rescaled so they lie between 0 and 1.\n","\n","It works by subtracting the min from the current value and dividing by the max.\n","\n","This always guarantees the range of the values, but can be severely affected by outliers"]},{"cell_type":"markdown","metadata":{},"source":["# N"]},{"cell_type":"markdown","metadata":{},"source":["# O"]},{"cell_type":"markdown","metadata":{},"source":["**Online learning**\n","\n","---\n","\n","The system can be trained incrementally by feeding it single data instances sequentially, either individually or in small \"mini-batches\"\n","\n","Each learning step must be fast and cheap so that it can learn on the fly\n","\n","Best used for quickly-changing data (such as stocks)\n","\n","<img src=\"img/online_learning.png\" width=\"25%\" >"]},{"cell_type":"markdown","metadata":{},"source":["**Overfitting**\n","\n","---\n","\n","When a model replicates its training dataset too closely and **lose the ability to generalise**. It happens when the model is **too complex** relative to the amount and noisiness of the training data.\n","\n","You can tell a model is overfitting when the training/validation error is low but the generalisation error is high\n","\n","<img src=\"img/overfitting.png\" width=\"25%\" >\n","\n","Solutions:\n","* Simplify the model by choosing one with fewer parameters (e.g. linear rather than polynomial)\n","* Reduce the number of attributes in the training dataset\n","* Restrict the model's parameters (regularisation)\n","* Gather more training data\n","* Reduce noise in training data (e.g. fix errors and remove outliers)"]},{"cell_type":"markdown","metadata":{},"source":["**One-hot encoding**\n","\n","---\n","\n","Creates one binary attribute (column) per text category that will be 1 if that category is true, or 0 if it is not.\n","\n","Standard way of encoding text categories as numbers.\n","\n","<img src=\"img/one_hot_encoding.jpg\" width=\"25%\">"]},{"cell_type":"markdown","metadata":{},"source":["# P"]},{"cell_type":"markdown","metadata":{},"source":["**Pipeline**\n","\n","---\n","\n","A sequence of data processing components to transform data from the source to the end goal\n","\n","<img src=\"img/pipeline.png\" width=\"25%\">"]},{"cell_type":"markdown","metadata":{},"source":["# Q"]},{"cell_type":"markdown","metadata":{},"source":["# R"]},{"cell_type":"markdown","metadata":{},"source":["**Regularisation**\n","\n","---\n","\n","Constraining a model to make it simpler and reduce the risk of **overfitting**\n","\n","e.g. force the slope of a linear model to be smaller to reduce degrees of freedom -> this may fit worse with training data but be more generalisable\n","\n","<img src=\"img/regularisation.png\" width=\"25%\">\n","\n","*in the above image, circles are training data and squares are new data*"]},{"cell_type":"markdown","metadata":{},"source":["**Reinforcement learning**\n","\n","---\n","\n","Where the learning system (agent) can observe the environment, carry out actions and then gets either a **reward** or **penalty**. It must then learn the best strategy over time to maximise the reward\n","\n","<img src=\"img/reinforcement.png\" width=\"25%\" />\n","\n","e.g. AIs can analyse historical results and then play millions of games against themselves to find the best policy to win"]},{"cell_type":"markdown","metadata":{},"source":["**Root Mean Square Error (RMSE)**\n","\n","---\n","\n","An equation that measures the **average error** a system makes in its predictions and **gives more weight to higher errors** (hence the square root).\n","\n","Used when outliers are rare.\n","\n","$ RMSE(X, h) = \\sqrt{\\frac{1}{m}\\Sigma_{i=1}^{m}{\\Big({h(x^{(i)})-y^{(i)}}\\Big)^2}} $\n","\n","Where $m$ is the number of instances in the validation dataset that you are evaluating RMSE on\n","\n","$x^{(i)}$ is a vector with all the feature values for the $i^{th}$ instance\n","\n","e.g. $x^{1}$ might be $\\left(\\begin{matrix}-118.29\\\\33.91\\\\\\begin{matrix}1,416\\\\38,372\\\\\\end{matrix}\\\\\\end{matrix}\\right)$ (the first item in the dataset)\n","\n","$y^{i}$ is simply the label (desired output for that instance)\n","\n","Finally, $X$ is a matrix containing all the feature values and $h$ is the prediction function that gives us the value to evaluate"]},{"cell_type":"markdown","metadata":{},"source":["**Random forest algorithm**\n","\n","---\n","\n","Used for regression or classification and works by training many decision trees on random subsets of data, and then averaging out their predictions"]},{"cell_type":"markdown","metadata":{},"source":["# S"]},{"cell_type":"markdown","metadata":{},"source":["**Semisupervised learning**\n","\n","---\n","\n","A machine learning system that can deal with a combination of labelled and unlabelled data. They often use a combination of supervised and unsupervised algorithms\n","\n","<img src=\"img/semisupervised.png\" width=\"25%\" />\n","\n","e.g. the unlabelled circles in the image above help classify a new instance (the cross) as a triangle and not a square - this can be done with a combination of clustering and classification algorithms\n","\n","e.g. Google Photos allows you to label a person once and then will identify all the photos that person has appeared in"]},{"cell_type":"markdown","metadata":{},"source":["**Supervised learning**\n","\n","---\n","\n","A machine learning system where you provide the desired solutions (called **labels**) in the training data\n","\n","<img src=\"img/supervised.png\" width=\"25%\" />\n","\n","Examples of supervised techniques:\n","* Classification\n","* Regression\n","* Neural networks"]},{"cell_type":"markdown","metadata":{},"source":["**Standardisation**\n","\n","---\n","\n","A method of bringing all data values onto the same scale. It subtracts the mean value from the current, and divides by the standard deviation.\n","\n","This results in data with a standard deviation of 1 and is good at **ignoring outliers**, but does not guarantee data lies **within a specific range**.\n","\n","<img src=\"img/standardisation.png\" width=\"25%\" />"]},{"cell_type":"markdown","metadata":{},"source":["# T"]},{"cell_type":"markdown","metadata":{},"source":["# U"]},{"cell_type":"markdown","metadata":{},"source":["**Underfitting**\n","\n","--- \n","\n","When the model is **too simple** to learn the underlying structure of your training data and its **predictions are always inaccurate**, even on training data\n","\n","Solutions:\n","* Select a more powerful model, with more parameters\n","* Feed better features to the learning algorithm (feature engineering)\n","* Reduce the constraints on the model (reduce any regularisation hyperparameters)"]},{"cell_type":"markdown","metadata":{},"source":["**Unsupervised learning**\n","\n","---\n","\n","A machine learning system where the training data is **unlabelled**. The system tries to learn without a teacher\n","\n","<img src=\"img/unsupervised.png\" width=\"25%\" />\n","\n","Examples of unsupervised techniques:\n","* Clustering\n","* Anomaly detection\n","* Visualisation/dimensionality reduction\n","* Association rule learning"]},{"cell_type":"markdown","metadata":{},"source":["**Utility/fitness function**\n","\n","--- \n","\n","A function that measures how well a model is performing so it can improve itself"]},{"cell_type":"markdown","metadata":{},"source":["**Univariate regression**\n","\n","---\n","\n","A regression task where the goal is to only predict **one value** per set of inputs"]},{"cell_type":"markdown","metadata":{},"source":["# V"]},{"cell_type":"markdown","metadata":{},"source":["# W"]},{"cell_type":"markdown","metadata":{},"source":["# X"]},{"cell_type":"markdown","metadata":{},"source":["# Y"]},{"cell_type":"markdown","metadata":{},"source":["# Z"]}],"metadata":{"colab":{"name":"Glossary.ipynb","provenance":[],"toc_visible":true},"interpreter":{"hash":"e1d159cb68591e48b67255eb41f9bda52bbf3bbfb0350e464e82f881b338c8a1"},"kernelspec":{"display_name":"Python 3.7.4 64-bit (conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":0}
